<!--
/* @license
 * Copyright 2020 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the 'License');
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an 'AS IS' BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <title>PBR Tone Mapping</title>
  <meta charset="utf-8">
  <meta name="description" content="Performance optimization for &lt;model-viewer&gt;">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/png" href="../assets/favicon.png"/>
  <link type="text/css" href="../styles/examples.css" rel="stylesheet" />
  <script type='module' src='https://modelviewer.dev/node_modules/@google/model-viewer/dist/model-viewer.min.js'></script>
  <script defer src="https://web3dsurvey.com/collector.js"></script>
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-169901325-1', { 'storage': 'none' });
    ga('set', 'referrer', document.referrer.split('?')[0]);
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
   <style>
    html {
      height:100%;
    }

    body {
      height: 100%;
      margin: 0;
      background-color: #f7f7f7;
      font-family: 'Rubik', sans-serif;
      font-size: 16px;
      line-height: 24px;
      color: rgba(0,0,0,.87);
      font-weight: 400;
      -webkit-font-smoothing: antialiased;
    }

    p {
      max-width: 700px;
      margin: 1em;
      text-align: left;
    }

    model-viewer {
      display: block;
      width: 100vw;
      height: 100vw;
      max-width: 600px;
      max-height: 600px;
    }

    img {
      width: 100vw;
      max-width: 600px;
    }

    figcaption {
      font-style: italic;
      max-width: 600px;
    }

    /* This keeps child nodes hidden while the element loads */
    :not(:defined) {
      display: none;
    }

    .icon-modelviewer-black {
    background-image: url(../assets/ic_modelviewer.svg);
    }
    .icon-button {
      margin-left: -4px;
      margin-right: 8px;
      width: 34px;
      height: 34px;
      background-size: 34px;
    }
    .inner-home {
      display: flex;
      align-items: center;
      font-size: 1.1em;
      text-decoration: none;
    }
    .home {
      padding: 20px;
      overflow: auto;
      white-space: nowrap;
    }
    .lockup {
      display: flex;
      align-items: center;
      margin-bottom: 6px;
      color: rgba(0,0,0,.87);
    }
    .attribute {
      white-space: pre-wrap !important;
      font-family: 'Roboto Mono', monospace;
      color: black;
    }
    .attribute:hover {
      text-decoration: underline;
      color: #444444;
    }
  </style>
</head>
<body>
  <div class="home lockup">
    <a href="../" class="sidebar-mv inner-home">
      <div class="icon-button icon-modelviewer-black inner-home"></div>
      <div class="inner-home"><span class="attribute">&lt;model-viewer&gt;</span></div>
    </a>
  </div>
  <div align="center">

    <h2>Tone Mapping Considerations for Physically-Based Rendering</h2>
    By <a href="https://github.com/elalish">Emmett Lalish</a>

    <p>Table of Contents:</p>
    <p>
      <a href="#purpose">The purpose of tone mapping</a><br/>
      <a href="#tradeoffs">Tradeoffs</a><br/>
      <a href="#needs">The needs of e-commerce</a><br/>
      <a href="#commerce">Commerce tone mapper</a><br/>
      <a href="#guarantees">Guarantees</a><br/>
    </p>
  
    <h3 id="purpose">The purpose of tone mapping</h3>

    <p>Tone mapping is a general term, which can refer to basically any color
    conversion function. Even separate operations that a photographer might
    apply in post processing, such as gamma correction, saturation, contrast,
    and even things like sepia can all be combined into a single resulting
    function that here we're calling tone mapping. However, we are only
    interested in hue-neutral functions and those are the only type of
    tone mapping functions we'll be discussing here. Therefore the focus will be
    primarily on luma, or brightness.</p>

    <p>The tone mapping function used by <code>&lt;model-viewer&gt;</code> is
    ACES, which is a standard developed by the film industry and is widely used
    for 3D rendering. Like most tone mapping curves, it is fairly linear in the
    central focus of its contrast range, then asymptotes out to smoothly
    compress the long tails of brights and darks into the required zero to one
    output range, the idea being that humans perceive less difference between
    over-bright and over-dark zones as compared to the bulk of the scene.
    However, since some output range is reserved for these extra-bright
    highlights, the range left over to represent the input range of matte
    baseColors is also reduced somewhat. This is why the paper-white sphere does
    not produce white pixels.</p>

    <p>Sometimes when working with matte objects and trying to compare output
    color to baseColor, this tone mapping compression will be noticed and
    identified as the source of the apparent tone discrepancy. The immediate
    thought is usually, let's fix this by not applying tone mapping! The problem
    is there is actually no such thing as "no tone mapping", since somehow the
    unbounded input range must be converted to the zero-to-one range that the
    encoder expects. If this step is not done, the encoder simply clamps the
    values, which amounts to a piecewise-linear tone mapping function with sharp
    corners that introduce perceptual errors for shiny objects, as shown in the
    example below.</p>

     <figure>
      <model-viewer
        id="toneMapping"
        src="../../shared-assets/models/silver-gold.gltf"
        skybox-image="../../shared-assets/environments/neutral.hdr"
        camera-controls
        alt="3D model of six example material spheres"
      >
      <label for="toneMapped">Tone Mapped: </label>
      <input id="toneMapped" type="checkbox">
      </model-viewer>
      <figcaption>Toggle ACES tone mapping to see the difference it makes.</figcaption>
    </figure>

    <p>Note that once again the shiny and matte white plastic spheres are
    indistinguishable, even without cranking up the exposure. Since half of the
    matte white sphere is now rendering pure white, there is no headroom for
    shiny highlights. Likewise, the top half of the sphere loses its 3D
    appearance since the shading was removed by clamping the values. Tick the
    checkbox to go back to ACES tone mapping for a quick comparison. Remember to
    look away and back again after switching; another trick of human perception
    is how dependent it is on anchoring. The yellow will look washed-out
    immediately after switching from saturated yellow, but this perception fades
    after looking around.</p>

    <p>This example also highlights a second key element of good tone mapping
    functions: desaturating overexposed colors. Look at the golden sphere
    (lower-left) and compare to the previous version with ACES tone mapping
    applied. The baseColor of a metal multiplies the incoming light, so a white
    light on a golden sphere produces a yellow reflection (fully saturated
    yellow, in this case of a fully saturated baseColor). With clamped tone
    mapping, the highlight is indeed saturated yellow, but this does not look
    perceptually right, even though you could make the argument it is physically
    correct.</p>

    <p>Good tone mapping curves like ACES not only compress the luma, but also
    push colors toward white the brighter they are. This is why the highlights
    on the golden sphere become white instead of yellow. This follows both the
    behavior of camera sensors and our eyes when responding to overexposed
    colored light. You can see this effect simply by looking at a candle's flame
    or a spark, the brightest parts of which tend to look white despite their
    color. Nvidia has helpfully provided more <a
    href="https://developer.nvidia.com/preparing-real-hdr">details</a> on tone
    mapping and HDR for the interested reader.</p>

    <p>One final way to avoid tone mapping that is sometimes suggested is to
    choose an exposure such that all pixels are inside the [0, 1] range, such
    that value clamping is avoided. For matte objects with low-dynamic-range
    lighting, this can give semi-decent results, but it breaks down completely
    for shiny objects, as shown in the following screenshot.</p>

    <figure>
      <img src="../assets/ExposureFit.png"/>
      <figcaption>Image of the above spheres with no tone mapping and exposure
      set to avoid clamping.</figcaption>
    </figure>

    <p>The trouble is that the specular highlights are orders of magnitude
    brighter than the majority of the scene, so to fit them into the output
    range requires the exposure to be lowered by more than a factor of 50. This
    kills the brightness and contrast of the majority of the scene, because of
    just a few small highlights. And this neutral environment does not have very
    high dynamic range; if you were to use an outdoor environment that includes
    the sun, the exposure would have to be so low that nearly the entire render
    would be black.</p>

    <p>Everything shown here is rendered to an 8-bit sRGB output, but HDR
    displays and formats are getting more common. Might we be able to avoid tone
    mapping by keeping the HDR of our raw image in an HDR output format? The
    short answer is no, because HDR displays may be high dynamic range compared
    to traditional SDR, but they are still orders of magnitude short of what our
    eyes experience in the real world, so all the same reasons for tone mapping
    still apply. However, it is important to note that the choice of tone
    mapping function should be dependent on the output format. Ideally it would
    even depend on the display's contrast ratio, its brightness settings, and
    the level of ambient lighting around it, but this data is unlikely to be
    available.</p>

    <h3 id="#tradeoffs">Tradeoffs</h3>

    <p>The difficulty with compressing a nearly infinite HDR range down to sRGB
    is the necessary loss of information. For the highlights to be discernable,
    the neutral contrast must be reduced, so a paper-white object must appear
    dimmer than 255 under diffuse lighting. For the highlights to desaturate
    appropriately and smoothly, the highest saturation colors of sRGB become
    unreachable under any lighting.</p>

    <p>The primary problem with ACES (and even AgX) tone mapping reported by
    e-commerce users is their significant loss of saturation. Many artists have
    been frustrated by their inability to produce a desired product color
    (generally dictated by marketing) with any combination of material
    properties and lighting, but few have realized that the tone mapping
    function is in fact the limiting factor. For example, the following figure
    shows the reachable set of ACES tone mapping, assuming sRGB inputs and
    outputs for both material properties and lighting, as specified by glTF.</p>

    <figure>
      <model-viewer
        id="toneMapping"
        src="../../shared-assets/models/silver-gold.gltf"
        tone-mapping="aces"
        camera-controls
        alt="3D model of six example material spheres"
      >
      </model-viewer>
      <figcaption>The ACES reachable colors.</figcaption>
    </figure>

    <p>Note that canary yellow, bright greens and blues are all impossible to
    output to the screen. This is partly because ACES comes from the film
    industry, where inputs may often be wider-gamut than sRGB, thus making more
    of these colors reachable. It is also because in film, the image detail is
    important across a wide spectrum of the HDR input range, so it makes sense
    to sacrifice more saturation for the sake of smoothly compressing a larger
    range. Finally, in film, the viewer is generally immersed, so the brain has
    no bright surrounding colors to compare to. This allows our perceptual
    system to compensate for the loss of saturation, allowing the image to still
    look good, instead of washed-out.</p>

    <h3 id="#needs">The needs of e-commerce</h3>

    <p>Unfortunately, the needs of e-commerce are quite different than the needs
    of film or gaming. On a website, a 3D product model will side-by-side with
    sRGB product photos, and a user may often compare the image on their screen
    to a printed image in a catalogue or to the physical product they have
    received. Of course it is exceedingly difficult to succeed in these
    comparisons, as there is no way to match the user's lighting environment to
    the photo studio's, nor to make a catalogue or screen emit light with the
    same intensity as a real-world reflection.</p>

    <p>What we can do is leverage the existing tools, processes, and experience
    of the artists, photographers, and marketers to match their existing product
    photography pipelines where they have been working to solve these problems
    already for years. The best way to make this easy for them is to ensure the
    baseColor assigned in the glTF shows through faithfully in the final render
    under neutral (grayscale) lighting. Faithful does not mean unchanged -
    certainly the brightness must vary to represent realistic shadowing and
    reflection, while metallic highlights must desaturate. However, hue should
    remain unchanged (except of course in the presence of colored, e.g. outdoor,
    lighting) and saturation should be retained as much as possible.</p>

    <p>The reason for adhering to the baseColor is simplicity and expediency:
    when product colors are updated, it will be much easier to modify and verify
    the sRGB values in the textures where they are relatively uniform, than in
    the final render where they vary greatly with lighting. And when a product
    render doesn't look "right", one can have confidence in the model and only
    vary the lighting to achieve the proper look, just as a photographer would.
    This allows for a convenient separation of concerns between product (model)
    and marketing (lighting).</p>

    <p>Commerce is much less interested in the detail of bright HDR regions.
    Studio lighting is intentionally crafted to avoid overexposure and focus on
    the important details of the product. While the brightness of highlights are
    orders of magnitude higher than sRGB, they are generally just the outlines
    of lights, whose blurred edges key our perception of the material's
    shininess. Details within this bright light are not important, so aggressive
    compression of the range of these highlights is much more reasonable than in
    film.</p>

    <p>We are focused on sRGB for both input (glTF) and output
    (web browsers), to meet the industry where it is today, which simplifies the
    tone mapping problem somewhat compared to the film industry. However,
    wider-gamut colorspaces and HDR monitors are working their way into the
    mainstream and we will need to address these challenges soon. The approach
    to tone mapping outlined in the following section should be generalizable to
    these situations, but there will be additional challenges beyond tone
    mapping as well.</p>

    <h3 id="#commerce">Commerce tone mapper</h3>

    <p>The Commerce tone mapper is designed to be simple to implement, fast to
    run, and faithfully reproduce color as much as possible while eliminating
    HDR artifacts around highlights.</p>

    <h3 id="#guarantees">Guarantees</h3>
    <h3 id="#down">White point</h3>

    <p>The tl;dr of this section is that you can safely skip it. It is a
    discussion of the difference between physically correct and practical
    approaches to color management.</p>

    <p>In developing this tone mapping function while addressing the needs of
    our own GStore, I found some peculiar data. I had always said the best way
    to choose the baseColor of your product material (we'll assume it is a
    simple, uniform color for now) was to scan it with a calibrated spectrometer
    under a controlled lighting environment. It turns out GStore does exactly
    this with all their Pixel products. However, they also have a marketing team
    that decides on correct sRGB colors to display for each product, using a
    person with a calibrated monitor in a light-controlled room and the product
    in-hand.</p>

    <p>These colors did not match. And not just brightness - even the hue varied
    significantly, at least to an artist's eyes. Which should we use? Like in
    most e-commerce shops, marketing makes the rules, and their color must be
    followed. But it bothered me; these differences were not random, like
    possible variations in human perception. What was causing the
    discrepancy?</p>

    <p>Finally I realized the root of at least most of the problem, when it
    occurred to me that all the marketing colors were generally red-shifted from
    the scanned ones. The white point of sRGB is D65 (the white point of your
    monitor), or 6500K if you've ever shopped for a lightbulb. The lighting
    marketing used with their calibrated monitor room was D50, to match the
    5000K bulbs they have in their retail stores, which is significantly yellower.</p>

    <p>To achieve PBR realism, we would need not grayscale lighting, which is
    D65 per the sRGB spec, but yellow D50 lighting. At first I championed this
    approach as the most physically-correct. However, all of our technical
    artists balked at this idea - it was hard to explain, meant keeping track of
    multiple colors, and introduced many places errors could subtly enter the
    pipeline.</p>

    <p>We decided instead to take the practical approach, of using the
    marketing-approved color as baseColor, with simple grayscale lighting to
    avoid skewing it. This isn't exactly correct according to PBR and the sRGB
    white point, but I think you'll find it very hard to detect the error.
    Considering other much bigger approximations we have baked in like operating
    on three colors instead of using a spectral renderer, smaller things are
    worth ignoring.</p>

    <p>However, when measuring color, remember that colorspace and white point
    are very important, and while a tool may be precise, it is hard to beat the
    accuracy of a person's calibrated eyeball, as long as their setup is
    well-controlled.</p>

  </div>
  <div style="margin-top:24px"></div>
  <div class="footer">
    <ul>
      <li>
        GeoPlanter, Mixer ©Copyright 2020 <a href="https://www.shopify.com/">Shopify
          Inc.</a>, licensed under <a
          href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a>.
      </li>
    </ul>
    <div style="margin-top:24px;" class="copyright">©Copyright 2018-2020 Google Inc. Licensed under the Apache License 2.0.</div>
    <div id='footer-links'></div>
  </div>

  <script type="module" src="./built/docs-and-examples.js">
  </script>
  <script type="module">
    (() => { initFooterLinks();})();
  </script>

  <script type="module">
    const toneMV = document.querySelector("#toneMapping");
    let threeRenderer;
    let scene;
    for (let p = toneMV; p != null; p = Object.getPrototypeOf(p)) {
      const privateAPI = Object.getOwnPropertySymbols(p);
      const renderer = privateAPI.find((value) => value.toString() == 'Symbol(renderer)');
      const sceneSym = privateAPI.find((value) => value.toString() == 'Symbol(scene)');
      if(renderer != null){
        threeRenderer = toneMV[renderer].threeRenderer;
      }
      if(sceneSym != null){
        scene = toneMV[sceneSym];
      }
      if(threeRenderer != null && scene != null){
        break;
      }
    }
    
    const makeToneMapped = (enabled) => {
      const {materials} = toneMV.model;
      const privateAPI = Object.getOwnPropertySymbols(materials[0]);
      const threeMaterials = privateAPI.find((value) => value.toString() == 'Symbol(correlatedObjects)');
      
      for(const material of materials){
        for(const threeMaterial of material[threeMaterials]){
          threeMaterial.toneMapped = enabled;
        }
      }
      scene.isDirty = true;
    };

    const checkbox = document.querySelector('#toneMapped');

    toneMV.addEventListener('load', () => {
      makeToneMapped(false);
      checkbox.addEventListener('change', () => {
        makeToneMapped(checkbox.checked);
      });
    });

    const envMV = document.querySelector("#environments");
    const envCycle = [
      "../../shared-assets/environments/spruit_sunrise_1k_HDR.hdr",
      "../../shared-assets/environments/whipple_creek_regional_park_04_1k.hdr",
      "../../shared-assets/environments/lebombo_1k.hdr",
      "../../shared-assets/environments/aircraft_workshop_01_1k.hdr",
      "../../shared-assets/environments/music_hall_01_1k.hdr",
      "../../shared-assets/environments/pillars_1k.hdr",
      "../../shared-assets/environments/neutral.hdr"
    ];

    setInterval(() => {
      const cycleIndex = envCycle.indexOf(envMV.skyboxImage);
      envMV.skyboxImage = envCycle[(cycleIndex + 1) % envCycle.length];
    }, 3000);
  </script>
</body>
</html>
